[{"categories":["posts"],"content":"本来想取名字叫“一次 zip 引发的血案”，但想了想还是改成现在这个名字了。\n众所周知，在计算机软件领域，总有人劝你不要更新软件，什么“最新的版本都是做实验，远不如老版本稳定”，“新版本都是加一些无关紧要占内存的东西，浪费硬盘”。曾经我不屑一顾，直到我在把我的游戏本从 Win10 更新到了 Win11 后也加入了旧版本至上教派。嗯，人不如故。\n秉持着只要还能用就永不更新得理念，ubuntu 无数次弹出更新提示，我刚开始还给他面子读一读信息，后来干脆连红点都不清理了，看都不看，直到酿成灾难😭\n初现端倪 某日我心血来潮，准备把电脑上的资料打包一下，上传的网盘，一是节省电脑的空间，二是整理电脑给我一个绝佳的摸鱼理由，于是我使用 zip 命令打包。\n当我正常打包了几个包后，在进行一次打包的时候发生了报错，报错信息写本文的时候已经找不到了，这里就不展示了。\n本着只要肯折腾就有折不完的腾的信念，我一如既往的读报错信息发现看不懂，然后直接 Google，经过简单的查阅，总有人遇到过和你一样的问题：应该是zip 版本太老了，导致目录名中有中文无法识别，最新的版本已经解决这个问题了。\n那好办啊，sudo apt install zip，嗯，还得是我们 linux，一行命令就解决了，吗？\n报错以下恐怖的错误：\n1 Error: 无法下载 http://archive.ubuntu.com/ubuntu/pool/main/z/zip/zip_3.0-14ubuntu0.2_amd64.deb 404 Not Found [IP: 91.189.91.81 80] 。 尝试运行 apt-get update 也报出大量错误，包括:\n1 Error: 无法下载 http://archive.ubuntu.com/ubuntu/pool/main/z/zip/zip_3.0-14ubuntu0.2_amd64.deb 404 Not Found [IP: 91.189.91.81 80]。 进入图形化界面系统更新处，点击更新弹出“下载软件仓库信息失败，检查您的网络设置”。\n这里的第一想法肯定是网络问题，但我连接其他服务器都很正常，难道是 ubuntu 的服务器崩了吗？ping -c 4 archive.ubuntu.com 却正常连接了：\n1 2 --- archive.ubuntu.com ping statistics --- 4 packets transmitted, 4 received, 0% packet loss, time 3003ms 这下不妙了，linux 下不怕报错，怕报错原因不清晰，404 not found 没找到对应的文件，难道是服务器的文件寻址有问题？因为问题比较特殊，单纯查无法下载的话更多的都是网络配置源配置一类的问题，这种详细描述定制化的问题还是交给 GPT 吧。\n问题溯源 GPT 先询问了我的版本，版本为 Ubuntu 24.10。然后让我告诉他我当前的更新源，我在终端上执行cat /etc/apt/sources.list.d/ubuntu.sources输出：\n1 2 3 4 5 6 7 8 9 Types: deb URIs: http://archive.ubuntu.com/ubuntu/ Suites: oracular oracular-updates oracular-backports Components: main restricted universe multiverse Signed-By: /usr/share/keyrings/ubuntu-archive-keyring.gpg Types: deb URIs: http://security.ubuntu.com/ubuntu/ Suites: oracular-security Components: main restricted universe multiverse Signed-By: /usr/share/keyrings/ubuntu-archive-keyring.gpg 嗯，标准的源路径，接下来 GPT 开始了长时间的思考检索，并告诉我了原因。\nUbuntu 24.10 (“Oracular Oriole”) 在 2025 年 7 月 10 日已进入生命周期结束（EOL）阶段，官方将其软件仓库归档到旧版本仓库（old-releases）。换言之，24.10 的软件包不再保留在 archive.ubuntu.com 或 security.ubuntu.com 等主镜像上。\n报错找不到 zip_3.0-14ubuntu0.2_amd64.deb，以及 GUI “下载软件仓库信息失败”，都是这种情况的典型表现。Ping 测试 archive.ubuntu.com 通畅只是说明网络正常，但对应的 24.10 仓库内容已经被移走，导致下载失败。\nubuntu.sources 文件中列出的 Suites 为 oracular 等，表示仍在查询 24.10 主仓库。由于 24.10 已过 EOL，这些源地址已不再有效，导致 apt update 和软件安装时均报 404 错误。\n也就是说，对于 Ubuntu 的系统版本，当他过时的时候会从主仓库中移除，通过原来的源不再能够找到对应需要的软件。\n看到这里我震惊了，用了快一年 Ubuntu 了，才知道还有这种策略。非常诡异的版本维护策略，兼容老版本不应该是新版本的一个必要条件吗！\n问题解决 主要应该采取两种方案：\n升级 Ubuntu 至受支持版本：Ubuntu 官方推荐的升级路径是从 24.10 升级到 Ubuntu 25.04。升级后即可使用活跃的仓库源继续获取更新，避免 404 问题。这是长远的解决方案。 修改 APT 源到旧版本仓库：如果暂时不升级系统，可以将软件源地址替换为 old-releases.ubuntu.com。具体操作可以编辑 /etc/apt/sources.list.d/ubuntu.sources 文件，将所有的 archive.ubuntu.com 和 security.ubuntu.com 替换为 old-releases.ubuntu.com 到这里我就非常无语了，那还能怎么办，折腾呗，了解了一下如果使用第二种方案的话软件源可能也比较过时，那还是升级我的系统吧，什么，你说重装一个 archlinux？那还是算了吧，最近实在忙，下一个电脑吧。\n备份 要更新/重装系统，备份是少不了的，这里给出一个备份的脚本命令，只用改一改你的外部存储设备就能直接用。要找外部设备的路径用 lsblk and df -h就可以了。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 # === 配置（请只修改 MOUNTPOINT 为你的实际挂载点） === MOUNTPOINT=\"/media/$USER/USB\" # \u003c- 把这里改成你的 U盘挂载路径（例如 /media/spike/USB） BACKUPDIR=\"$MOUNTPOINT/backup-$(date +%F)\" USERNAME=\"$USER\" HOMEDIR=\"$HOME\" # === 检查挂载点是否存在 === if [ ! -d \"$MOUNTPOINT\" ]; then echo \"错误：找不到挂载点 $MOUNTPOINT 。请确认 U盘已插入并已挂载 (查看 lsblk / df -h)。\" exit 1 fi # === 创建备份目录 === sudo mkdir -p \"$BACKUPDIR\" sudo chown \"$USER\":\"$USER\" \"$BACKUPDIR\" # === 1) 备份 /home/\u003cuser\u003e（排除 .cache） === echo \"正在打包 /home/$USERNAME ...\" sudo tar -C / -czpf \"$BACKUPDIR/home-$USERNAME.tar.gz\" --exclude=\"home/$USERNAME/.cache\" \"home/$USERNAME\" # === 2) 备份 /etc === echo \"正在打包 /etc ...\" sudo tar -C / -czpf \"$BACKUPDIR/etc-backup.tar.gz\" /etc # === 3) 保存已安装包列表 === echo \"导出已安装包列表...\" dpkg --get-selections \u003e \"$BACKUPDIR/installed-packages.list\" # === 4) 备份 /etc/apt 源（含 ubuntu.sources 等） === echo \"复制 /etc/apt ...\" sudo cp -a /etc/apt \"$BACKUPDIR/etc-apt-backup\" # 如果你有 ubuntu.sources 文件，单独拷贝（若不存在不会报错） sudo cp -a /etc/apt/sources.list.d/ubuntu.sources \"$BACKUPDIR\" 2\u003e/dev/null || true # === 5) 备份 ~/.ssh 与 ~/.gnupg（以 tar 保留权限） === echo \"打包 ~/.ssh 和 ~/.gnupg ...\" # 注意：若 ~/.gnupg 很大或有权限问题，可能需要先关闭 gpg-agent sudo tar -C \"$HOMEDIR\" -czpf \"$BACKUPDIR/ssh-gnupg-$USERNAME.tar.gz\" .ssh .gnupg || true # === 6) 生成校验文件（sha256） === echo \"生成 sha256 校验...\" cd \"$BACKUPDIR\" sha256sum *.tar.gz \u003e checksums.sha256 sha256sum -c checksums.sha256 || echo \"注意：校验部分文件可能失败，请检查输出。\" # === 7) 同步并安全卸载的提醒 === sync echo \"备份完成，文件位于：$BACKUPDIR\" echo \"请在卸载 U盘前确认文件无误（例如：ls -lh $BACKUPDIR ； sha256sum -c $BACKUPDIR/checksums.sha256 在另一台机器或以后验证）\" 当然这是 AI 生成的。注意脚本不要用 sudo 运行，这样会更改你的路径，正常的 bash bashup.bash 或者 chmod +x bashup.bash ./bashup.bash就可以了。\n临时更改 APT 源 在完成备份以后，需要把 把 APT 源临时指向 old-releases.ubuntu.com,为什么需要把源临时更改呢？\n24.10 的包已被从主镜像（archive.ubuntu.com / security.ubuntu.com）移走 —— 这会造成 apt update 报 404，导致 update-manager/GUI 无法下载仓库信息。因此临时把 URIs 指向 old-releases.ubuntu.com，能恢复索引与让你安装升级工具（不是长期方案，只为完成升级准备）。官方/社区文档也建议此法用于 EOL 版本的升级准备。\n先将原来的源保存一份 sudo cp /etc/apt/sources.list.d/ubuntu.sources /etc/apt/sources.list.d/ubuntu.sources.bak\n然后更改源列表：\n1 2 3 4 sudo sed -i \\ -e 's|http://archive.ubuntu.com/ubuntu/|http://old-releases.ubuntu.com/ubuntu/|g' \\ -e 's|http://security.ubuntu.com/ubuntu/|http://old-releases.ubuntu.com/ubuntu/|g' \\ /etc/apt/sources.list.d/ubuntu.sources 然后更新当前系统的所有包，减少后续更新时的冲突。\n1 2 3 4 sudo apt update sudo apt upgrade -y sudo apt full-upgrade -y # 或 sudo apt dist-upgrade sudo apt autoremove -y 升级系统 安装并确认升级工具存在 sudo apt install update-manager-core ubuntu-release-upgrader-core -y\n接着编辑 /etc/update-manager/release-upgrades，确保 Prompt=normal\n运行 sudo do-release-upgrade，接着就是漫长的升级，重新下载加载内核、各种各样的桌面组件。经过漫长的煎熬，无时无刻不在担心奇怪的报错，所幸完成了更新。这时再运行确认版本 cat /etc/os-release，输出：\n1 2 3 4 5 6 7 8 9 10 11 12 13 PRETTY_NAME=\"Ubuntu 25.04\" NAME=\"Ubuntu\" VERSION_ID=\"25.04\" VERSION=\"25.04 (Plucky Puffin)\" VERSION_CODENAME=plucky ID=ubuntu ID_LIKE=debian HOME_URL=\"https://www.ubuntu.com/\" SUPPORT_URL=\"https://help.ubuntu.com/\" BUG_REPORT_URL=\"https://bugs.launchpad.net/ubuntu/\" PRIVACY_POLICY_URL=\"https://www.ubuntu.com/legal/terms-and-policies/privacy-policy\" UBUNTU_CODENAME=plucky LOGO=ubuntu-logo 终于完成了更新😭。如果我没有记错的话，再更新完之后你本地记录更新源就会被自动的覆写掉，再次执行 cat /etc/apt/sources.list.d/ubuntu.sources，输出：\n1 2 3 4 5 6 7 8 9 10 11 Types: deb URIs: http://archive.ubuntu.com/ubuntu Suites: plucky plucky-updates plucky-backports Components: main restricted universe multiverse Signed-By: /usr/share/keyrings/ubuntu-archive-keyring.gpg Types: deb URIs: http://security.ubuntu.com/ubuntu Suites: plucky-security Components: main restricted universe multiverse Signed-By: /usr/share/keyrings/ubuntu-archive-keyring.gpg 此时再执行一次对当前所有源更新：\n1 2 3 4 sudo apt update sudo apt upgrade -y sudo apt full-upgrade -y # 或 sudo apt dist-upgrade sudo apt autoremove -y 就可以快乐的 zip打包啦！嗯，一次 zip 引发的血案。\n经历了这场灾难后，我只能说下一个电脑锁定 macOS，至少不会再是 Ubuntu，当然更不会是 Windows。还有一件事，Chatgpt 真的是我的救命恩人啊😭\n","description":"","tags":null,"title":"Ubuntu EOL: 旧版本主义者的灾难","uri":"/blog_Hspikes/posts/technology/linux/ubuntu-eol/"},{"categories":["posts"],"content":"这个实验主要是巩固邮件服务器以及客户端原理，并简要的了解 STMP 协议。实验时一定要选对实验用的邮箱服务器，不然可能遇到一些诡异的问题。不推荐校园邮箱、QQ、Google，这些要么会报诡异的错误，要么需要 SSL。\nSMTP 协议 SMTP 协议是一个常见的 Email 应用的协议，在 TCP 上在服务器与客户端之间传输报文，端口号默认固定为 port = 25，报文主要以 ASCII 码的形式传递。\n因为报文主要以 ASCII 码的形式传递，无法表示一般的二进制文件，也无法表示中文，要传输这些无法以 ASCII 码表示的报文，需要通过 Base64 将二进制编码为 ASCII 码，再通过 MIME 协议传输，我们实验中没有完成这部分，高情商的表示为以后留下提升空间。但我们仍用到了 Base64 编码来进行用户认证。\nSMTP 协议一个典型的客户端与服务器交流流程如下：\nconnect: 客户端发出连接请求，服务器回复 220 表示建立连接。\nHELO: 客户端发送报文 HELO，服务器回应 250 OK。这一步是可以省略的，但大部分客户端实现仍然会打招呼，礼貌总是好的。\nAUTH: 现在邮件服务器都需要认证身份，客户端发送 AUTH LOGIN 表示开始认证身份，在收到服务器的指示之后分别向服务器发送用户名与认证密钥。在现有的 SMTP 协议中要求用户名与密钥均要使用 Base64 编码，否则无法正确识别，这是为了避免密钥中带有 \\n一类特殊转义字符的缘故。这个设计显得十分诡异，但是是协议要求的缘故，现有的实现均是如此。\nFrom-To: 在完成认证后，告知服务器邮件发送方以及接收方，发送方需要与认证身份匹配，交流成功均会收到 250 确认码。\nMessage: 向服务器发送 DATA 表明开始发送邮件，邮件必须以头部开始，头部要包含 from, to, subject and Content-type, 正文部分以 \\r\\n.\\r\\n 结尾。发送结尾信息后，邮件服务器会发送 250 确认码。\nQUIT: 客户端发送表明连接结束，我用于实验的 163 邮箱退出时一句 Bye 都没有，世间的冷漠莫过于此。\n代码实现 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 from socket import * import base64 def check_recv(csock, expmsg): recv = csock.recv(1024).decode() print(recv) if(recv[:3] != expmsg): print (expmsg + ' reply not received from server.') exit(1) return endmsg = \"\\r\\n.\\r\\n\" mailserver = (\"smtp.163.com\",25) fromaddr = \"***@163.com\" rcptaddr = \"***@qq.com\" username = base64.b64encode(\"***@163.com\".encode()).decode() password = base64.b64encode(\"***\".encode()).decode() clientSocket = socket(AF_INET, SOCK_STREAM) clientSocket.setsockopt(SOL_SOCKET, SO_REUSEADDR, 1) msg = \"\\r\\n I love computer network!\" clientSocket.connect(mailserver) check_recv(clientSocket, '220') heloCommand = 'HELO smtp.163.com\\r\\n' clientSocket.send(heloCommand.encode()) check_recv(clientSocket, '250') clientSocket.send(\"AUTH LOGIN\\r\\n\".encode()) check_recv(clientSocket, '334') clientSocket.sendall((username + '\\r\\n').encode()) check_recv(clientSocket, '334') clientSocket.sendall((password + '\\r\\n').encode()) check_recv(clientSocket, '235') clientSocket.send((f\"MAIL FROM:\u003c{fromaddr}\u003e\" + '\\r\\n').encode()) check_recv(clientSocket, '250') clientSocket.send((f\"RCPT TO:\u003c{rcptaddr}\u003e\" + '\\r\\n').encode()) check_recv(clientSocket, '250') clientSocket.send('DATA\\r\\n'.encode()) check_recv(clientSocket, '354') message = \"from: hspikes \u003c****@163.com\u003e\\r\\n\" message += \"to: hspikes \u003c****@qq.com\u003e\\r\\n\" message += \"subject: Hello\\r\\n\" message += \"Content-Type: text/plain\\t\\n\" message += msg clientSocket.send(message.encode()) clientSocket.send(endmsg.encode()) check_recv(clientSocket, '250') clientSocket.send('QUIT'.encode()) clientSocket.close() 可以看到我们用一个函数包装了接收服务器消息的流程，避免了过于繁琐的 if。代码没有什么很特别的地方，基本就是按照 SMTP 标准的流程走一趟，注意到用户名和密钥的编码，收发以及头部的格式就好了。\n","description":"","tags":null,"title":"lab3: 邮件客户端","uri":"/blog_Hspikes/posts/technology/%E5%A5%97%E6%8E%A5%E5%AD%97%E7%BC%96%E7%A8%8B/lab3-%E9%82%AE%E4%BB%B6%E5%AE%A2%E6%88%B7%E7%AB%AF/"},{"categories":["posts"],"content":"对实验一的纯粹的实验性质程序加“一点点”小功能，可以更好的把玩一下。包含文件路径处理、多进程处理一系列简单改造。\n支持不同文件类型 服务器现阶段返回的固定是 HTML 文件，改造成根据客户端的请求返回目录下的任意文件。\n使用 Python 自带的 mimetypes 模块（Python 神了），根据文件扩展名自动推断 MIME 类型。在读取文件时不再使用 read 来读，不能正确处理二进制文件，换成 open。发送的时候也应当避免使用 encode，否则会损坏二进制数据。\n改造后的文件处理部分：\n1 2 3 4 5 6 7 8 9 10 11 content_type, _ = mimetypes.guess_type(filepath) if content_type is None: content_type = \"application/octet-stream\" # 默认二进制 # 读取文件（二进制） with open(filepath, \"rb\") as f: outputdata = f.read() ... header += f\"Content-Type: {content_type}\\r\\n\" ... connectionSocket.send(outputdata) 安全性 现阶段的文件访问没有做任何特别的处理，也就是说如果我在服务器上层放一张图片 HTTP.png，http://localhost:8080/../HTTP.png就可以直接访问到这个文件。这好像没什么但如果我是 /../../etc/passwd 你不炸了吗？\n浏览器路径规范化与错误请求 但我在用浏览器测试的时候先发现这样一个问题，确实我发现了我访问 http://localhost:8080/../HTTP.png 但浏览器地址栏却是 http://localhost:8080/HTTP.png 。并且发现服务器端报出 Unexpected error: list index out of range 的错误，这涉及浏览器的一个机制：浏览器的路径规范化。\nlocalhost:8080/../HTTP.png 时，浏览器会路径归一化(Normalization)。/../HTTP.png 会被规整为 /HTTP.png，这是浏览器的“用户体验逻辑”，目的是防止用户在地址栏看到奇怪的 ..，也避免和文件系统“上级目录”混淆。这时你打出报文就会发现收到的报文其实是 GET /HTTP.png HTTP/1.1 。\n那么为什么会报出 list index out of range 呢？能报这个错误的代码应当只有一句 filename = message.split()[1]。 而在访问 /../HTTP.png 时，浏览器在地址栏输入一个“特殊 URL”时，可能会先发一次探测请求（甚至是异常格式，比如只发 GET，没有路径），所以服务器就会解析崩溃，加上合理的健壮性判断即可。\n1 2 3 4 5 6 7 8 9 parts = message.split() if len(parts) \u003c 2: # 非法请求，直接返回 400 Bad Request header = \"HTTP/1.1 400 Bad Request\\r\\n\\r\\n\" connectionSocket.send(header.encode()) connectionSocket.close() continue filename = parts[1] 至此我就不再打算用浏览器测试了，浏览器自己有很多隐含的机制，我又不是在测试浏览器。我用自己写的客户端试了试，确实服务器可以收到 Request message: GET /../index.html HTTP/1.1 并且成功返回，下面我们就解决这个问题。\n目录规范 HTTP 请求里的路径本质就是一个字符串，目录穿越漏洞（Directory Traversal），真实 Web 服务器都会防御。关键在于把 URL 里的路径归一化（处理 .、..、重复斜杠等情况）并且确保归一化后的路径仍然在你的根目录（document root）之下。\n我们直接导入 GPT 给出的处理方案，并简单讲解。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 import os from urllib.parse import unquote # 定义允许访问的根目录（示例） WEB_ROOT = os.path.abspath(\"./source\") def safe_path(request_path: str) -\u003e str | None: # 浏览器或客户端可能把 .. 编码成 %2e%2e。在解析前应把百分号编码解回来再处理。 request_path = unquote(request_path) # 去掉开头的 \"/\" rel_path = request_path.lstrip(\"/\") # 归一化路径（会处理 .. 和 . 以及多余的斜杠） normalized = os.path.normpath(rel_path) # 拼接成绝对路径 abs_path = os.path.abspath(os.path.join(WEB_ROOT, normalized)) # 检查是否仍然在 WEB_ROOT 内 if os.path.commonpath([WEB_ROOT, abs_path]) == WEB_ROOT: return abs_path else: return None filepath = safe_path(filename) if filepath is None: header = \"HTTP/1.1 403 Forbidden\\r\\n\\r\\n\" connectionSocket.send(header.encode()) connectionSocket.close() return 注意 Python 的函数语法，还是比较别致的。normpath 不会把相对路径“丢掉”开头的 ..，只合并冗余，而 os.path.abspath(...) 会解析 ..。最后再判断解析完成后的路径是否合规即可。\n多进程服务器 这里差评，直接询问 GPT Python 里面启动多进程的方式，GPT 竟然不给出进程回收的机制，问他他还说我问的专业 (也是把我夸的心花怒放了，感谢 ICS 课)。\n和 ICS 课上的机制几乎一致，fork 再子进程父进程分开处理。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 def handle_client(connectionSocket, addr): try: message = connectionSocket.recv(2048).decode() print(\"Request message:\", message) # … 这里放你之前的文件处理逻辑 … connectionSocket.close() except Exception as e: print(\"Error:\", e) connectionSocket.close() signal.signal(signal.SIGCHLD, signal.SIG_IGN) ... connectionSocket, addr = serverSocket.accept() pid = os.fork() if pid == 0: # 子进程 serverSocket.close() # 子进程里不用监听 socket handle_client(connectionSocket, addr) sys.exit(0) # 子进程结束 else: # 父进程 connectionSocket.close() # 父进程里不用这个连接 至于回收子进程，我学到一个以前课上完全没提到过的机制，自动回收。\n直接注册信号 signal.signal(signal.SIGCHLD, signal.SIG_IGN)，忽略这个信号。如果父进程把 SIGCHLD 设置成忽略，Linux 内核就认为：“既然你不关心子进程的退出状态，我就不需要给你留着了。”于是，子进程退出时，内核会立刻自动回收，不会留下僵尸进程。\n这个我仔细询问了 GPT，查阅了一些资料放置大模型幻觉，是真的！这个是现在 Linux 内核的惯例的处理，而不是 POSIX 的强制标准，在 ICS 的课上都没有讲过这个机制。\n这里我们直接就用了这个机制而没有注册一个回收函数，即通过传统的 waitpid 的方式来进行回收，这种方式确实非常简便，但是就父进程失去了从子进程处得到信息并记录日志的机会，我们这里就不做的太复杂就这样了。\n至此我们基本完成了服务器的改造，可以完成基本的文件传输功能。下面我们对客户端端做出配套的改造。\n配套客户端 我们需要的效果是输入一个文件，直接到对应的服务器下去下载目标文件，那么必须要有一个输入。然后我们要将服务器发回的报文分段，将 Head 分离出来解读，如果报文正常，将 Body 部分存储下来。\n我们直接采用命令行的输入方式，即把请求的文件直接作为脚本运行时的参数代入，Python 没有 main 函数的设计还是十分诡异。参数直接存储在变量 sys.argv 中，显然这是一个参数列表。\n1 2 3 4 5 if len(sys.argv) \u003c 2: print(f\"Usage: python3 {sys.argv[0]} \u003cfilename\u003e\") sys.exit(1) filename = sys.argv[1] 按照先前的方式接收报文，在收到报文之后重要的就是要对报文进行分割解读。根据 HTTP 协议的标准格式，只需要找到两个连续的换行符即可把 Head 和 Body 分割出来。\n1 2 3 4 5 6 7 8 separator = b'\\r\\n\\r\\n' header_end = response.find(separator) if header_end == -1: print(\"Invalid HTTP response\") sys.exit(1) header_bytes = response[:header_end].decode(errors='replace') body = response[header_end + 4:] 头部可以直接解码判断，输出在终端上判断情况。\n1 2 print(\"===HTTP Header===\") print(header_bytes) 如果头部表明文件正常传输了，那么我们就根据头部存储文件即可，否则报出相应的错误。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 content_type = \"application/octet-stream\" for line in header_bytes.split(\"\\r\\n\"): if line.lower().startswith(\"content-type:\"): content_type = line.split(\":\", 1)[1].strip() break status_line = header_bytes.split(\"\\r\\n\")[0] if not status_line.startswith(\"HTTP/1.1 200\"): print(\"Request failed:\", status_line) sys.exit(1) with open(filename, \"wb\") as f: f.write(body) print(f\"Body saved to {filename}\") 可以注意到文件的默认类型为 application/octet-stream 即二进制文件，然后根据首部行的内容分割出实际的文件类型，但其实我们这里不需要文件类型了，只是为了展示实际应当采用的分割策略。\n接着就只用读到什么写入什么，注意判断一下异常即可。\n1 2 3 4 5 6 7 8 9 status_line = header_bytes.split(\"\\r\\n\")[0] if not status_line.startswith(\"HTTP/1.1 200\"): print(\"Request failed:\", status_line) sys.exit(1) with open(filename, \"wb\") as f: f.write(body) print(f\"Body saved to {filename}\") To be done 至此基本就能实现一个简单的文件传输了，但是实际测试就会发现：传输效率实在不高。一个 200 MB 的视频文件几乎传了 20 min 才完成，核心是收发包的过程很多处理很低效。如果以后还有机会的话就调一调这一部分。\n","description":"","tags":null,"title":"lab1pro: 基础CS文件传输","uri":"/blog_Hspikes/posts/technology/%E5%A5%97%E6%8E%A5%E5%AD%97%E7%BC%96%E7%A8%8B/lab1pro-%E5%9F%BA%E7%A1%80cs%E6%96%87%E4%BB%B6%E4%BC%A0%E8%BE%93/"},{"categories":["posts"],"content":"记录我在做《计算机网络：自顶向下方法》实验过程的一些问题以及掌握的知识。同时也包含了 python 语言的一些入门。\n因为自己没有系统的去学习过 python 语言，所以在编程的过程中一边一葫芦画瓢，一边借助 Copilot 辅助。在以前用的相对偏少，这次频繁使用后深感现在生成式 AI 的强大，就连在复制实验提供的代码框架时，仅仅复制了一半的框架，自动补全另一半框架和实验提供框架完全一致。这个或许是数据库中包含，没什么了不起的。然而框架中的每一部分都可以轻松细化，并且根据你的要求对答如流，我觉得或许程序员的末日已经到了吧，要只争朝夕的提桶跑路了😭\nAnyway, 回归正题，建立连接的流程不再赘述，忘了去看笔记，直接进入代码环节。\nWebserver 实现 框架代码 实验提供的框架代码如下:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 #import socket module from socket import * import sys # In order to terminate the program serverSocket = socket(AF_INET, SOCK_STREAM) #Prepare a sever socket #Fill in start #Fill in end while True: #Establish the connection print('Ready to serve...') connectionSocket, addr = #Fill in start #Fill in end try: message = #Fill in start #Fill in end filename = message.split()[1] f = open(filename[1:]) outputdata = f.read() #Send one HTTP header line into socket #Fill in start #Fill in end #Send the content of the requested file to the client for i in range(0, len(outputdata)): connectionSocket.send(outputdata[i].encode()) connectionSocket.send(\"\\r\\n\".encode()) connectionSocket.close() except IOError: #Send response message for file not found #Fill in start #Fill in end #Close client socket #Fill in start #Fill in end 模块导入 最开始的部分类似于 C/C++ 的导入库，可以看到在这个代码中就包含了两种库的写法。\nfrom socket import *: 这里的 * 表示导入模块中的所有成员，直接导入到当前命名空间。 import socket: 这种方式是将模块整体导入命名空间，使用时要加上模块前缀名，例如accept要写做socket.accept。 两者分别的优势非常显然，一个简洁，一个清晰避免冲突。根据需要使用就可以了。\nSocket 模块 只写一些常用的函数，一些常量在函数实例中会有解释。\nsocket(): 用于创建一个套接字（socket）。 语法：socket(family, type, proto=0) family：地址族（如 AF_INET 表示 IPv4，AF_INET6 表示 IPv6）。 type：套接字类型（如 SOCK_STREAM 表示 TCP，SOCK_DGRAM 表示 UDP）。 proto：协议号，通常默认为 0。 bind(): 将套接字绑定到指定的地址和端口。 语法：socket.bind(address) address 是一个元组 (host, port)。 示例：s.bind(('localhost', 8080)) listen(): 使套接字进入监听模式，等待客户端连接（仅适用于 TCP）。 语法：socket.listen(backlog) backlog：允许的最大连接数。 示例：s.listen(5) accept(): 接受客户端连接，返回一个新的套接字和客户端地址。 语法：socket.accept() 示例：connection, addr = s.accept() connect(): 主动连接到服务器（仅适用于客户端）。 语法：socket.connect(address) 示例：s.connect(('example.com', 80)) send(): 用于发送数据。 recv(): 接收数据。 语法：socket.recv(bufsize) bufsize：接收缓冲区大小。 示例：data = s.recv(1024) close(): 关闭套接字。 语法：socket.close() 注意到除了创建套接字，其余的函数都需要类似类方法一般指定对象调用。\n那么第一个补充块的内容就很简单了，我们只需要生成一个地址，然后绑定上就可以了。我这里的地址是随便编的，反正我本地的 8080 号端口确实没有被占用。\n1 2 3 server_address = ('0.0.0.0',8080) serverSocket.bind(server_address) serverSocket.listen(5) HTTP 报文解读 一个典型的 HTTP 请求报文可能如下：\n1 2 3 4 GET /filename.html HTTP/1.1 Host: localhost:8080 ... 第一行是请求行，包含 HTTP 方法、请求文件以及协议版本。第二行首部行标识主机地址以及端口号。随后一个空行表明头部行结束。后续跟上数据。\n相应报文则应当由如下格式：\n1 2 3 4 HTTP/1.1 200 OK Content-Type: text/html ... 解读完全类似，包含状态码以及状态码解释，第二行为响应头部，注意就算是 404 不会返回任何数据仍然应当包含相应头部！\n利用 python 方法实现对报文拆分：\nsplit()：按照指定的分隔符（默认为空格）将字符串分割成一个列表。 splitline()：按照换行符（\\n 或 \\r\\n）将字符串分割成一个列表。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 connectionSocket, addr = serverSocket.accept() # 先调用 accept 建立连接 try: message = connectionSocket.recv(2048).decode() print(\"Request message:\", message) filename = message.split()[1] # 在命令行找到文件名，注意用 decode 对字符串解码 f = open(filename[1:]) outputdata = f.read() header = \"HTTP/1.1 200 OK\\r\\n\" header += \"Content-Type: text/html\\r\\n\" header += \"\\r\\n\" connectionSocket.send(header.encode()) # 先发送头部，注意要用 encode 对字符串编码 注意到我们这里用了异常处理，最为这段中最为典型的异常肯定是 open 没有找到对应的文件，也就可以对应我们的 404，我们如法炮制补充 except 的情况。\n1 2 3 4 5 6 7 except IOError: header = \"HTTP/1.1 404 Not Found\\r\\n\" header += \"Content-Type: text/html\\r\\n\" header += \"\\r\\n\" connectionSocket.send(header.encode()) # 发个 404 回去 connectionSocket.close() 这样下来最为基础的功能就完成了，我们可以简单测试，在终端运行 python3 webserver.py。再在浏览器访问对应端口 localhost:8080/index.html。我的 html 用的是网上随便薅下来的，确保和代码在同一个目录下，能够测试就可以了。\n终止机制 下面部分就已经超出了基本的要求，是一些我自己实验中拓展内容。\n如果你测试时频繁终止进程并重启你就会发现这样的问题，当我在终端上暴力的终止程序，使用 ctrl+shift+c 终端上进程确实停止运行了，然而我立刻再次运行则会报错：Traceback (most recent call last): File “/home/hspike/code/class/network/mylab/lab1/init_webserver.py”, line 8, in \u003cmodule\u003e serverSocket.bind(server_address) OSError: [Errno 98] Address already in use\n显然它的意思是我采用固定的 IP 和端口号仍在被占用，因为我暴力的终止导致了没有 close 导致了这个结果。但是一段时间后不改变代码中的 IP 与端口号就能够正常运行了，应该是操作系统介入释放了这个端口。\n当你暴力终止程序（如按下 Ctrl+Shift+C），程序会立即停止运行，导致套接字没有被正确关闭。此时：操作系统会将套接字标记为 TIME_WAIT 状态。在 TIME_WAIT 状态下，操作系统会暂时保留该端口，以确保之前的连接完全关闭，避免数据包的延迟传输影响新连接。\n操作系统会在一段时间后（通常是 30 秒到 2 分钟，具体取决于系统配置）自动释放端口。 这是 TCP 协议的机制，用于确保旧连接的数据包不会干扰新连接。\n为了避免暴力终止程序导致资源未释放，可以捕获终止信号（如 SIGINT），并在程序退出前正确关闭套接字。也就是说注册一个信号处理函数。在 ICS 课上讲过信号处理异常控制流的机制，这里不再赘述，只展示 python 语法。注意需要 signal 库。\n1 2 3 4 5 6 7 8 import signal def graceful_shutdown(signum, frame): print(\"Shutting down server...\") serverSocket.close() sys.exit(0) signal.signal(signal.SIGINT, graceful_shutdown) 这样我们就优雅的终止进程了。\nClient 实现 Client 的实现就相对简单许多了，仿照 Server 的语法，代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 from socket import * import sys import signal clientSocket = socket(AF_INET,SOCK_STREAM) clientSocket.connect(('localhost',8080)) message = 'GET /index.html HTTP/1.1\\r\\nHost: localhost\\r\\n\\r\\n' clientSocket.send(message.encode()) response = b\"\" while True: part = clientSocket.recv(4096) if not part: break response += part print(response.decode()) 我们不再做详细的讲解。\nServer 中断连接处理 这里提一个遇到的问题，在初版的 Client 我是这样写的：\n1 2 3 4 5 6 7 8 9 10 11 from socket import * import sys import signal clientSocket = socket(AF_INET,SOCK_STREAM) clientSocket.connect(('localhost',8080)) message = 'GET /index.html HTTP/1.1\\r\\nHost: localhost\\r\\n\\r\\n' clientSocket.send(message.encode()) response = clientSocket.recv(4096) print(response.decode()) 我认为本地测试的 html 文件非常小，只用接收一次便可以了，然而运行结果出乎意料，报文竟然只到达了以下部分：\n1 2 3 4 5 HTTP/1.1 200 OK Content-Type: text/html \u003c!DOCTYPE html\u003e \u003c!--STATUS OK--\u003e\u003chtm 并且切换到服务器端发现服务器进程已经终止了，核心原因是客户端只接受了很少部分报文便关闭连接，导致服务器 Send 函数抛出异常，进而导致了程序终止。\n显然客户端因为各种各样的原因中断连接很常见，不能客户端断了服务器就停摆吧，增加一个中断连接的异常处理。\n1 2 3 4 except(ConnectionResetError, BrokenPipeError): # 这些异常表示用户中断了连接 print(\"Connection with client was reset or closed.\") connectionSocket.close() 这样就优雅的处理了这个问题。\n但这里还有一个隐含的问题应当注意，代码的 4096 表示的是 4096 bytes，足足 4K。你应当意识到了问题，4K 表示一个纯文本的 html 文件错错有余，怎么会没有接收完呢？\n原因在于HTTP 相应报文的分块传输，客户端只调用一次接收，所以并没有完整的接收到整个相应。\nTo be done 这里完成了本地基础 C/S 交互，或许你意识到了这种方法借助于 TCP 提供的服务，甚至实现了进程间的通信。\n进一步改进应当有两点：\n服务器端建立连接交由子进程处理：手段在 ICS 中介绍过，明天我会进一步实现这个功能。 主机之间通信测试：暂时手上只有一个主机，明天会用另一台主机作为客户端，参与测试。 ","description":"","tags":null,"title":"lab1: 基础CS模式入门","uri":"/blog_Hspikes/posts/technology/%E5%A5%97%E6%8E%A5%E5%AD%97%E7%BC%96%E7%A8%8B/lab1-%E5%9F%BA%E7%A1%80cs%E6%A8%A1%E5%BC%8F%E5%85%A5%E9%97%A8/"},{"categories":["posts"],"content":"在编写搭建个人博客网站时曾遇到这样一个问题：将图片文件存储在本地时没有任何问题，可以正常打开，网站也可以正常渲染，然而当通过 git 上传到 github 之后，部署到 github page 后图片却无法正常渲染。经过原因调查发现在 github 仓库中对应的图片文件无法正常打开，下载后 Linux 环境也无法正常打开。\n进一步查阅发现是 git config 配置的问题~~(虽然问题解决后也没能成功渲染)~~，由于以前没有详细研究关于 git 的设置，一怒之下查询了相关的资料整理了一下。\nGit 配置综述 层级结构 Git 的配置有层级之分，共有三层，类似局部变量与全局变量的关系，更高的层级有更低的优先级：\n系统级（–system）：对整个操作系统上的所有用户生效。配置文件通常在 /etc/gitconfig。 全局级（–global）：对当前用户生效。配置文件在 ~/.gitconfig 或 Windows 的 C:\\Users\u003c用户名\u003e\\.gitconfig。 仓库级（默认）：只对当前 Git 仓库生效。配置文件在仓库的 .git/config。 语法规则 这些配置项的语法规则类似结构体遵循\u003csection\u003e.\u003ckey\u003e。其中 section 时区块名，比如 core, user, branch…\n查看设置 这些配置文件默认状态下均是隐藏的，在 Linux 下以位于 . 开头的 .git 中，ls 带参数 -a 即可查看。\n对于一个特定项目，可以运行git config --list --show-origin命令，一是显示当前项目的所有配置，二是显示这些配置的来源文件。\n需要查看某一项具体配置，直接运行命令git config ***即可。\n比如本博客项目的仓库 git 配置如下：\n1 2 3 4 5 6 7 8 9 10 11 [core] repositoryformatversion = 0 filemode = true // git 会跟踪文件的可执行权限 bare = false // 是否为裸仓库，即没有工作区，常用于远程仓库 logallrefupdates = true // git 会为所有引用保留日志，在 .git/logs/ 中 [remote \"origin\"] url = git@github.com:Hspikes/blog_Hspikes.git fetch = +refs/heads/*:refs/remotes/origin/* // 在 fetch 时将远程仓库所有分支都同步到本地 [branch \"main\"] remote = origin merge = refs/heads/main 全局配置只有在你第一次设置了--global配置后才会自动生成。至于全局的配置如下：\n1 2 3 4 5 6 [user] email = ***@*** name = Hspikes [core] editor = vim autocrlf = false 可以看到全局配置基本上只约束了用户名邮箱地址、信息默认编辑器之类的，至于那个 autocrlf 我们下文会讲到。\n本项目 git 没有系统级别的配置，通常系统级均是关于服务器多人协作、企业模版等场景下运用，个人的电脑上往往都不会进行系统级设置。\n常见配置 这里的常见配置自然不包括 username, email… 一类的易懂的配置，而是总结一些较难理解却容易出错的配置。\ncore.autocrlf 显然根据区块名称这属于核心配置，auto 自动处理某些问题，crlf 代表换行相关的处理。控制的是 Git 在提交和检出文件时，是否自动转换换行符。\n一个人尽皆知的问题是不同系统的换行符不一样，Windows → CRLF (\\r\\n), Linux/macOS → LF (\\n)。Git 为了避免“同一文件在不同系统上显示换行不一致”，提供了这个自动转换机制。\n这个设置共有三种模式:\ntrue: 提交时：Git 会把 CRLF → LF(保证仓库里都是 LF)；检出时：Git 会把 LF → CRLF。 input: 提交时：Git 会把 CRLF → LF；检出时：不做转换(保持仓库里的 LF)。 false: Git 不做任何转换，提交和检出都保持原样。 我所遇到的问题便是 autocrlf 设置为 true 并且 git 提交时错误的把本属于二进制文件的图片文件 png 识别为了文本文件，导致图片文件内容被损坏。\n最合适的做法是在 .gitattributes 中声明哪些是二进制文件，比如：\n1 2 3 *.png binary *.jpg binary *.pdf binary 我这里由于开发环境，直接偷了懒，更改了全局设置，等以后出问题时再来清算吧😋\npull.rebase pull 的默认方式是 fetch + merge，若 pull.rebase = true，则默认方式为 fetch + rebase。前者会保留分支的分流历史，后者会合并两者而不保留分流历史。\n","description":"","tags":null,"title":"git-config: 关于 git 设置的一些问题","uri":"/blog_Hspikes/posts/technology/git-config/"},{"categories":["posts"],"content":"如题，总之就是各种茶，尝试复制一些奶茶店的味道🙃 (但0.5分糖)\n珍珠奶茶 最为经典的入门款，在家自己做珍珠实在太麻烦，还要自己揉面，否定！实在想要珍珠调节口感的话可以直接买一些现成的珍珠。\n原料准备红茶+奶+少许白糖，由于试验性质，原料也没必要准备过于奢侈，一般的口粮茶和盒装奶就可以了。糖的量自己控制，我个人不喜欢太甜，但是如果完全不加糖的话调味会比较诡异，一小勺白糖就可以了。\n先熬红茶，也不用讲究丢下去暴力烹煮，先大火煮沸后换小火烹煮，煮到微微闻到中药味非常浓稠。因为调配奶茶最长使用的是茶精和炼乳，这样茶味和奶味都比较重，所以用现煮的茶熬煮一定要熬的比较浓稠才能有足够的茶味。\n当红茶熬煮完成之后加入一定量的牛奶，小火慢煮知道第一次沸腾，一定要注意牛奶沸腾以后由于奶皮的缘故会噗出，注意到这个现象后动作迅速关火搅动，煮的过程就结束了。牛奶不要熬煮过久，因为熬煮过长时间后牛奶会严重沉积，导致口感非常差~~(别问我怎么知道的)~~。\n这种方式煮出来的奶茶热的味道一般，但冷冻后不说和标准的珍珠奶茶天差地别也能说是完全一样了，糖度可以自己调节。\n","description":"","tags":null,"title":"总之就是各种茶","uri":"/blog_Hspikes/posts/spike%E5%AE%B6%E4%BB%8A%E5%A4%A9%E5%90%83%E4%BB%80%E4%B9%88/%E6%80%BB%E4%B9%8B%E5%B0%B1%E6%98%AF%E5%90%84%E7%A7%8D%E8%8C%B6/"},{"categories":["posts"],"content":"写在结局之前 根据诺克斯宅邸的状况，能够实现偷诺克斯的画的人只有诺克斯家里面的人，排除掉无名的仆人就只剩下了琼和诺克斯两个人。\n琼的关键问题在于作为女秘书难以一个人把尸体搬运到棺材当中，诺克斯的问题在于最开始难以栽赃卡基斯，因为琼看到杯子是卡基斯已经死之后，此时诺克斯已经无法再设局了。况且如果是诺克斯下手，他主动来到警局阐述关于画的事那一段动机过于诡异。\n这么看来两者都无法独立作案，但我实在不理解最后打字机的线索，应该还有什么疏忽之处，这里就猜诺克斯凶手吧。\n诡计鉴赏 最开始拿到这本书时一看目录，推理小说有 40 章 400 页，拖沓如占星术杀人魔法也不过 350 页，不敢想希腊棺材观感会有多糟糕。然而作者选择了连环诡计来吸引读者的主义，连环诡计的设计炉火纯青，完全足以支撑起 400 页的内容，也算是洗刷了我对埃勒里·奎因糟糕的印象了。\n第一个案就远超预期，根据茶壶的描述很容易意识到水量不正常，然而很难根据领带猜到卡基斯非盲这一点进而联想到卡基斯是凶手，这个我认为是最为精彩的一个诡计 (虽然很快被推翻了)。\n第二案就很稀疏平常了，烟草中的钥匙和没烧完的遗书栽赃的意味太明显了，又没有给出额外的线索。\n最后检察官作为凶手的设计确实出乎意料，推理小说的惯性思维作用下根本不会联想警局的一方人会出现凶手，完全没有抓住作者关于检察官的任何线索暗示，也算是棋差一着了。\n","description":"","tags":null,"title":"希腊棺材之谜: 连环诡计典范","uri":"/blog_Hspikes/posts/whodunit/%E5%B8%8C%E8%85%8A%E6%A3%BA%E6%9D%90%E4%B9%8B%E8%B0%9C/"},{"categories":["posts"],"content":"诡计鉴赏 以前老师告诉过我科研难点不仅仅在于解决问题，更在于找到问题。这对推理小说也是同理，只要找到了惯用手的角度切入思考，配合两个追查者状态的变化答案就很显然，但难点在于找到这个角度。\n最后解密时一个核心是玫瑰花纹的垃圾桶，但里面是空的，一般没读到最后很难注意到这个东西，只能后来再找，看到这大家的反映应该都一样去哥哥调查案发现场那一段找垃圾桶，但那个时候也是空的，那肯定就是中间某人丢了东西进去。如果有电子版 PDF 直接搜索玫瑰花纹一下就能定位，可惜是纸质的。\n至于案件本身两人都想行凶在现场相遇这个设定颇具想象力，可惜不是核心诡计。中途润一的不在场证明过于简陋，可以说攻破的方法不计其数，而且提到数码相机后正确答案也十拿九稳，实在称不上诡计。东野的诡计质量确实不太行。\n佳世子试图作为模仿犯连现场有泥土都知道，这设定太不合理，这种连环杀人细节都不应当纰漏就是为了防止模仿犯，警方失职太严重了😅\n","description":"","tags":null,"title":"谁杀了她","uri":"/blog_Hspikes/posts/whodunit/%E8%B0%81%E6%9D%80%E4%BA%86%E5%A5%B9/"},{"categories":["posts"],"content":"本文 markdown 相关的内容主要参考网站 Markdown教程，记下一些自己常用常忘的语法。至于 latex，GPT 是我的唯一指定 latex 导师。这个框架下 markdown 的渲染不等价与所有框架的 markdown 渲染，并且数学公式的渲染也与真实 latex 环境有些差异，但无关紧要。\n题外话，这个框架下，如果你要写二级或者三级标题建议采取 2n 个 #，如果只差一个 #，感觉标题层次不太清晰。\nLatex 常用数学符号表 分析代数 代码 效果 描述 |·| $ |·| $ 范数，这里渲染不太对，请直接看源码 \\nabla $ \\nabla $ \\ \\partial $ \\partial $ \\ \\mathbb{R} $ \\mathbb{R} $ 渲染不够华丽啊，而且很慢 \\to $ \\to $ \\ \\mapsto $ \\mapsto $ \\ 大小比较 代码 效果 描述 \\geq $ \\geq $ \\ \\leq $ \\leq $ \\ \\neq $ \\neq $ \\ 因果推理 代码 效果 描述 \\forall $ \\forall $ \\ \\exists $ \\exists $ \\ \\because $ \\because $ \\ \\therefore $ \\therefore $ \\ \\Leftarrow $ \\Leftarrow $ \\ \\Leftrightarrow $ \\Leftrightarrow $ \\ \\neg $ \\neg $ \\ \\in $ \\in $ \\ 希腊字符 代码 效果 描述 \\lambda $ \\lambda $ \\ 其他 Markdown 空格 文字段落内空格 $~~~$，这里是 $~~~$ 效果。\n制表 | Syntax | Description | Test Text | | :--- | :----: | ---: | | Header | Title | Here's this | | Paragraph | Text | And more | Syntax Description Test Text Header Title Here’s this Paragraph Text And more 一个简易的表格示意，第二行指定了对齐方式。\nEmoji 直接从 Emojipedia 中复制粘贴就好了。下面粘贴一些我用过的表情。类我就不分了，应该用不了几种。\n⭐🥰😅🙃😋😭\n","description":"","tags":null,"title":"Markdown and latex","uri":"/blog_Hspikes/posts/technology/markdown/"},{"categories":["posts"],"content":"因为从 7 月中才开始写新番杂记，所以这个季度的杂谈不包含前一两话吧。不过话又说回来这个季度看的不太多。\n追番进度表 名称 进度 当前评价 恋人不行 第十一话 ⭐⭐⭐⭐⭐ 原教旨主义挺好 小城日常 第九话 ⭐⭐⭐⭐⭐ 友谊地久天长 这届侦探不太行 第十一话 ⭐⭐⭐⭐⭐ 已完结 琉璃的宝石 第十话 ⭐⭐⭐⭐⭐ 还有青龙的 call back，女主的成长塑造的太优秀了 完结杂谈 这届侦探不太行 前期最吸引我的是一些对传统侦探推理题材的解构，推理小说忠实爱好者看前面几集的内容真的捧腹大笑。\n可惜传统推理小说能解构的内容是有限的，到了中期笑点就更多的集中在了人设反差一类上，走传统搞笑番的道路，但作为传统搞笑番仍然是很优秀的。\n整体无论剧情还是人设（其实主要是小卷）我都很喜欢，可惜动画太穷了，而且看最终话的做法，第二季的希望也比较渺茫了，依依不舍😭\n评价留档 恋人不行 第三话 ⭐⭐⭐⭐⭐ 非常有趣，周指活。但怎么感觉这一话没有之前富呢？穷穷的。 第四话 ⭐⭐⭐⭐⭐ 屑粉毛也是出手了，太爱紫阳花了 第五话 ⭐⭐⭐⭐⭐ 全程笑容没停下来过 第六话 ⭐⭐⭐⭐⭐ 纱月也太可爱了吧，王总：我很忠诚，我的妻子也很幸福 第七话 ⭐⭐⭐⭐⭐ 一如既往的有趣 第九话 ⭐⭐⭐⭐⭐ 终于等到紫阳花篇了，该结束这场闹剧了 第十话 ⭐⭐⭐⭐⭐ 粉毛太屑了，结尾实在绷不住 第十一话 ⭐⭐⭐⭐⭐ 原教旨主义挺好 小城日常 第二话 ⭐⭐⭐⭐$~~~~$ 感觉风评不是很行，但我的观感还是很好的🥰 第三话 ⭐⭐⭐$~~~~~~~~$ 开场笑话没有太 get，整体节奏不太抓得住注意力 第四话 ⭐⭐⭐⭐$~~~~$ call back 很有趣 第五话 ⭐⭐$~~~~~~~~~~~~$ 想法挺有意思的，但实在不太好看，ed 风格挺特别的 第六话 ⭐⭐$~~~~~~~~~~~~$ 看睡着了 第八话 ⭐⭐⭐$~~~~~~~~$ 第九话 ⭐⭐⭐⭐⭐ 友谊地久天长 这届侦探不太行 第五话 ⭐⭐⭐⭐⭐ 对侦探小说爱好者来说很好笑，很多会心一笑的梗 第六话 ⭐⭐⭐⭐⭐ 全程笑不停，甚至还有 call back，无敌了 第七话 ⭐⭐⭐$~~~~~~~~$ 比较无趣，几个笑点都很一般，失去了先前推理迷笑点特色 第八话 ⭐⭐⭐$~~~~~~~~$ 远不如前几话，有关推理侦探的梗很少，失去了核心看点 第九话 ⭐⭐⭐$~~~~~~~~$ 看完就忘了讲了什么了 第十话 ⭐⭐⭐⭐$~~~~$ 笑点比起前两话进步不少，沦为一般搞笑番了 第十一话 ⭐⭐⭐⭐⭐ 已完结 琉璃的宝石 第四话 ⭐⭐⭐$~~~~~~~~$ 制作很好，女主有点熊孩子看得我血压高 第五话 ⭐⭐⭐⭐$~~~~$ 愿意写这种成长型人设的真不多了，我也想要挂我二作的学姐 第六话 ⭐⭐⭐⭐⭐ 渐入佳境，看到女主调查犯错那一段感觉太恐怖了 第七话 ⭐⭐⭐⭐⭐ 这话真的无敌，整体节奏非常舒适，看到中间讲薄膜反射时会心一笑，涨知识了。 第八话 ⭐⭐⭐⭐⭐ 一如既往的维持超高质量 第九话 ⭐⭐⭐⭐⭐ 风姐实在可爱，结尾的升华不如第七话 第十话 ⭐⭐⭐⭐⭐ 总体不如前两化，但还是非常优秀。两小孩很可爱 第十话 ⭐⭐⭐⭐⭐ 还有青龙的 call back，女主的成长塑造的太优秀了 ","description":"","tags":null,"title":"2025.7新番杂记","uri":"/blog_Hspikes/posts/animation/%E6%96%B0%E7%95%AA%E6%9D%82%E8%AE%B0/2025.7/"},{"categories":["posts"],"content":"","description":"","tags":null,"title":"玫瑰的名字","uri":"/blog_Hspikes/posts/whodunit/%E7%8E%AB%E7%91%B0%E7%9A%84%E5%90%8D%E5%AD%97/"},{"categories":["posts"],"content":"This blog is to test whether the blog site is working properly.\n世人都晓神仙好，只是功名忘不来！\n古今将相今何在，荒冢一堆草没了。\n世人都晓神仙好，只是金钱忘不了！\n终朝只恨聚无多，即到多时眼闭了。\n中文字体也正常。\n1 printf(\"Hello world!\"); 但我更喜欢 cout\u003c\u003c\"Hello world!\";\n代码块也正常。\n插入图测试：\nseem to be all right?\n","description":"","tags":null,"title":"Hello World: 一些基本功能测试","uri":"/blog_Hspikes/posts/zothers/hello-world/"},{"categories":["posts"],"content":"This blog is to test whether the blog site is working properly.\nWhen n is a positive interger, $\\Gamma(n+1)=n!$, and\n$$ B(p,q)=\\frac{\\Gamma(p+q)}{\\Gamma(p)\\Gamma(q)} $$\nseem to be all right?\n","description":"","tags":null,"title":"Math Test: 数学公式书写测试","uri":"/blog_Hspikes/posts/math/hello-world/"}]
